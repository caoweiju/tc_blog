---
title: 线上日志分析必备命令和实践
date: 2019-01-14 23:48:22
tags:
- log
- commend
- linux
categories: 
- 日志
---
# 线上日志查看基础
 查看线上机器的一些信息和基础命令：
* du、df查看大小相关
* cat、zcat、less、tail、head查看文件内容
* grep、awk处理文件内容
* sort、uniq、wc统计
* scp文件传输

# du、df查看大小相关
1. df 查看系统挂载磁盘大小 
    * `df [选项]... [FILE]...`
        文件`-a`, --all 包含所有的具有 0 Blocks 的文件系统
        文件`--block-size={SIZE}` 使用 {SIZE} 大小的 Blocks
        文件`-h`, --human-readable 使用人类可读的格式(预设值是不加这个选项的...)
        文件`-H`, --si 很像 -h, 但是用 1000 为单位而不是用 1024
        文件`-i`, --inodes 列出 inode 资讯，不列出已使用 block
        文件`-k`, --kilobytes 就像是 --block-size=1024
        文件`-l`, --local 限制列出的文件结构
        文件`-m`, --megabytes 就像 --block-size=1048576
        文件`--no-sync` 取得资讯前不 sync (预设值)
        文件`-P`, --portability 使用 POSIX 输出格式
        文件`--sync` 在取得资讯前 sync
        文件`-t`, --type=TYPE 限制列出文件系统的 TYPE
        文件`-T`, --print-type 显示文件系统的形式
        文件`-x`, --exclude-type=TYPE 限制列出文件系统不要显示 TYPE
        文件`-v` (忽略)
        
        常见使用实例：
        ````
        df -h
        ````

2. du会显示指定的目录或文件所占用的磁盘空间
    * `du [-abcDhHklmsSx][-L <符号连接>][-X <文件>][--block-size][--exclude=<目录或文件>][--max-depth=<目录层数>][--help][--version][目录或文件]`
        参数说明：
        `-a或-all` 显示目录中个别文件的大小。
        `-b或-bytes` 显示目录或文件大小时，以byte为单位。
        `-c或--total` 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。
        `-D或--dereference-args` 显示指定符号连接的源文件大小。
        `-h或--human-readable` 以K，M，G为单位，提高信息的可读性。
        `-H或--si` 与-h参数相同，但是K，M，G是以1000为换算单位。
        `-k或--kilobytes` 以1024 bytes为单位。
        `-l或--count-links` 重复计算硬件连接的文件。
        `-L<符号连接>或--dereference<符号连接>` 显示选项中所指定符号连接的源文件大小。
        `-m或--megabytes` 以1MB为单位。
        `-s或--summarize` 仅显示总计。
        `-S或--separate-dirs` 显示个别目录的大小时，并不含其子目录的大小。
        `-x或--one-file-xystem` 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。
        `-X<文件>或--exclude-from=<文件>` 在<文件>指定目录或文件。
        `--exclude=<目录或文件>` 略过指定的目录或文件。
        `--max-depth=<目录层数>` 超过指定层数的目录后，予以忽略。
        使用实例：查看当前文件夹的一级内容大小
        ````
        du -h --max-depth=1
        ````

## cat、zcat、less、tail、head查看文件内容
1. ` cat` 命令用于连接文件并打印到标准输出设备上
    * `cat [-AbeEnstTuv] [--help] [--version] fileName`
        `-n 或 --number`：由 1 开始对所有输出的行数编号。
        `-b 或 --number-nonblank`：和 -n 相似，只不过对于空白行不编号。
        `-s 或 --squeeze-blank`：当遇到有连续两行以上的空白行，就代换为一行的空白行。
        `-v 或 --show-nonprinting`：使用 ^ 和 M- 符号，除了 LFD 和 TAB 之外。
        `-E 或 --show-ends` : 在每行结束处显示 $。
        `-T 或 --show-tabs`: 将 TAB 字符显示为 ^I。
        `-A, --show-all`：等价于 -vET。
        `-e`：等价于`"-vE"`选项；
        `-t`：等价于`"-vT"`选项；
 
2. `zcat`t命令用于不真正解压缩文件，就能显示压缩包中文件的内容的场合。

3. `head`显示档案的开头至标准输出中，默认head命令打印其相应文件的开头10行
    * `head [参数]... [文件]... `
        `-q` 隐藏文件名
        `-v` 显示文件名
        `-c<字节>` 显示字节数
        `-n<行数>` 显示的行数

4. `tail`用于查看文件的内容，有一个常用的参数` -f `常用于查阅正在改变的日志文件
    * `tail[必要参数][选择参数][文件] `
        `-f` 循环读取
        `-q` 不显示处理信息
        `-v` 显示详细的处理信息
        `-c<数目>` 显示的字节数
        `-n<行数>` 显示行数
        `--pid=PID 与-f合用`,表示在进程ID,PID死掉之后结束. 
        `-q, --quiet, --silent` 从不输出给出文件名的首部 
        `-s, --sleep-interval=S 与-f合用`,表示在每次反复的间隔休眠S秒 
5. `less`可以随意浏览文件
    * `less [参数]  文件`
        `-b <缓冲区大小>` 设置缓冲区的大小
        `-e`  当文件显示结束后，自动离开
        `-f`  强迫打开特殊文件，例如外围设备代号、目录和二进制文件
        `-g`  只标志最后搜索的关键词
        `-i`  忽略搜索时的大小写
        `-m`  显示类似more命令的百分比
        `-N`  显示每行的行号
        `-o <文件名>` 将less 输出的内容在指定文件中保存起来
        `-Q`  不使用警告音
        `-s`  显示连续空行为一行
        `-S`  行过长时间将超出部分舍弃
        `-x <数字>` 将“tab”键显示为规定的数字空格
        `/字符串`：向下搜索“字符串”的功能
        `?字符串`：向上搜索“字符串”的功能
        `n`：重复前一个搜索（与 / 或 ? 有关）
        `N`：反向重复前一个搜索（与 / 或 ? 有关）
        `b`  向后翻一页
        `d`  向后翻半页
        `h`  显示帮助界面
        `Q`  退出less 命令
        `u`  向前滚动半页
        `y`  向前滚动一行
        `空格键` 滚动一行
        `回车键` 滚动一页
        `[pagedown]`： 向下翻动一页
        `[pageup]`：   向上翻动一页

## grep、awk处理文件内容
1. `grep`用于查找文件里符合条件的字符串。
    * `grep [-abcEFGhHilLnqrsvVwxy][-A<显示列数>][-B<显示列数>][-C<显示列数>][-d<进行动作>][-e<范本样式>][-f<范本文件>][--help][范本样式][文件或目录...]`
        `-a 或 --text` : 不要忽略二进制的数据。
        `-A<显示行数> 或 --after-context=<显示行数>` : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。
        `-b 或 --byte-offset` : 在显示符合样式的那一行之前，标示出该行第一个字符的编号。
        `-B<显示行数> 或 --before-context=<显示行数>` : 除了显示符合样式的那一行之外，并显示该行之前的内容。
        `-c 或 --count` : 计算符合样式的列数。
        `-C<显示行数> 或 --context=<显示行数>或-<显示行数>` : 除了显示符合样式的那一行之外，并显示该行之前后的内容。
        `-d <动作> 或 --directories=<动作>` : 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。
        `-e<范本样式> 或 --regexp=<范本样式> `: 指定字符串做为查找文件内容的样式。
        `-E 或 --extended-regexp` : 将样式为延伸的普通表示法来使用。
        `-f<规则文件> 或 --file=<规则文件>` : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。
        `-F 或 --fixed-regexp` : 将样式视为固定字符串的列表。
        `-G 或 --basic-regexp` : 将样式视为普通的表示法来使用。
        `-h 或 --no-filename` : 在显示符合样式的那一行之前，不标示该行所属的文件名称。
        `-H 或 --with-filename` : 在显示符合样式的那一行之前，表示该行所属的文件名称。
        `-i 或 --ignore-case` : 忽略字符大小写的差别。
        `-l 或 --file-with-matches` : 列出文件内容符合指定的样式的文件名称。
        `-L 或 --files-without-match` : 列出文件内容不符合指定的样式的文件名称。
        `-n 或 --line-number` : 在显示符合样式的那一行之前，标示出该行的列数编号。
        `-q 或 --quiet或--silent` : 不显示任何信息。
        `-r 或 --recursive` : 此参数的效果和指定"-d recurse"参数相同。
        `-s 或 --no-messages` : 不显示错误信息。
        `-v 或 --revert-match` : 显示不包含匹配文本的所有行。
        `-V 或 --version` : 显示版本信息。
        `-w 或 --word-regexp` : 只显示全字符合的列。
        `-x --line-regexp `: 只显示全列符合的列。
        `-y `: 此参数的效果和指定"-i"参数相同。
2. awk处理文本文件的语言，是一个强大的文本分析工具。
    * `awk '{pattern + action}' {filenames}`或者`awk [-F  field-separator]  'commands'  input-file(s)`
        
    1. `awk -F, '$2 ~ /test/ {print $2"\t"$4}' log.txt`
        使用`-F,`的作用是每行按照`,`分割，`$1`-`$2`-`$n`就是分割的结果的对应顺序的值
        `$2 ~ /th/`就是需要分割的第二个数据需要和`test`匹配的上
        `{print $2$4}`输出分割结果的第二个和第四个
        处理的信息是`log.txt`
    2. `awk -F '[:=]' '{match($5,/.*uc_name=(.*)&extend=test.*/,a); print a[1]}' log.txt`
        `-F '[:=]'`使用多个分隔符，先使用`:`分割，然后在对分割结果使用`=`二次分割。
        `'{match($5,/.*uc_name=(.*)&extend=test.*/,a); print a[1]}'`对分割后的第五个结果处理，需要能够匹配上其中的正则，并把匹配结果放到数组`a`中，其中`a`数组的结果`a[0]`是全匹配的结果，`a[1]`是正则匹配的子表达式结果，并输出子表达式。
        
## sort、uniq、wc统计
1. `sort`用于将文本文件内容加以排序。
    * `sort [-bcdfimMnr][-o<输出文件>][-t<分隔字符>][+<起始栏位>-<结束栏位>][--help][--verison][文件]`
        `-b` 忽略每行前面开始出的空格字符。
        `-c` 检查文件是否已经按照顺序排序。
        `-d` 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。
        `-f` 排序时，将小写字母视为大写字母。
        `-i` 排序时，除了040至176之间的ASCII字符外，忽略其他的字符。
        `-m` 将几个排序好的文件进行合并。
        `-M` 将前面3个字母依照月份的缩写进行排序。
        `-n` 依照数值的大小排序。
        `-o<输出文件>` 将排序后的结果存入指定的文件。
        `-r` 以相反的顺序来排序。
        `-t<分隔字符>` 指定排序时所用的栏位分隔字符。
        `+<起始栏位>-<结束栏位>` 以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。
2. `uniq`用于检查及删除文本文件中重复出现的行列，需要与 sort 命令结合使用[一定要排序，不然去重无效，只会去除相邻的重复项]
    * `uniq [-cdu][-f<栏位>][-s<字符位置>][-w<字符位置>][--help][--version][输入文件][输出文件]`
        `-c或--count` 在每列旁边显示该行重复出现的次数。
        `-d或--repeated` 仅显示重复出现的行列。
        `-f<栏位>或--skip-fields=<栏位>` 忽略比较指定的栏位。
        `-s<字符位置>或--skip-chars=<字符位置>` 忽略比较指定的字符。
        `-u或--unique` 仅显示出一次的行列。
        `-w<字符位置>或--check-chars=<字符位置>` 指定要比较的字符。
3. `wc`计算文件的Byte数、字数、或是列数，若不指定文件名称、或是所给予的文件名为"-"，则wc指令会从标准输入设备读取数据。
    * `uniq [-cdu][-f<栏位>][-s<字符位置>][-w<字符位置>][--help][--version][输入文件][输出文件]`
        `-c或--bytes或--chars` 只显示Bytes数。
        `-l或--lines` 只显示行数。
        `-w或--words` 只显示字数。
## scp文件传输
1. `scp`是`linux`系统下基于ssh登陆进行安全的远程文件拷贝命令[`需要配置ssh登入，密码或者公钥免密`]
    * `scp [-1246BCpqrv] [-c cipher] [-F ssh_config] [-i identity_file] [-l limit] [-o ssh_option] [-P port] [-S program] [[user@]host1:]file1 [...] [[user@]host2:]file2`
        `-1`： 强制scp命令使用协议ssh1
        `-2`： 强制scp命令使用协议ssh2
        `-4`： 强制scp命令只使用IPv4寻址
        `-6`： 强制scp命令只使用IPv6寻址
        `-B`： 使用批处理模式（传输过程中不询问传输口令或短语）
        `-C`： 允许压缩。（将-C标志传递给ssh，从而打开压缩功能）
        `-p`：保留原文件的修改时间，访问时间和访问权限。
        `-q`： 不显示传输进度条。
        `-r`： 递归复制整个目录。
        `-v`：详细方式显示输出。scp和ssh(1)会显示出整个过程的调试信息。这些信息用于调试连接，验证和配置问题。
        `-c cipher`： 以cipher将数据传输进行加密，这个选项将直接传递给ssh。
        `-F ssh_config`： 指定一个替代的ssh配置文件，此参数直接传递给ssh。
        `-i identity_file`： 从指定文件中读取传输时使用的密钥文件，此参数直接传递给ssh。
        `-l limit`： 限定用户所能使用的带宽，以Kbit/s为单位。
        `-o ssh_option`： 如果习惯于使用ssh_config(5)中的参数传递方式，
        `-P port`：注意是大写的P, port是指定数据传输用到的端口号
        `-S program`： 指定加密传输时所使用的程序。此程序必须能够理解ssh(1)的选项。

## 实践
线上日志结构：
````
183.250.223.158 [16/Dec/2018:23:57:15 +0800] "GET /log?skdata=sdadadad111%22username%33%3ftestets%22fsfdsfssadadasd%34fdsfs%34  HTTP/1.0" 200 2 "-" "testiPhone/d64556" "120.188.90.136" "jsdgajdsad" "dasdadd" "test" "ceshi"
````
分析数据命令：
````
cat /home/logs/2018/12/access.2018-12-16.log | grep -E  'skdata.*username' | awk '{match($5,/.*username%33%3f(.*)%22fsfdsfssadadasd.*/,a); print a[1]}' | sort | uniq -c | wc -l
````

1. `cat`查看某一天的日志文件，访问日志一般文件一天记录一份

2. `grep`查看符合需求的访问日志，本实例使用正则匹配`-E`来筛选出符合要求的详情页访问日志，输出

3. `awk`分析符合要求的详情页访问日志，把每行详情页访问日志中`$5`【空格分割的第五个字符串,本实例就是以`/log?`开头的字符串】去匹配一个正则`.*username%33%3f(.*)%22fsfdsfssadadasd.*`，并把结果放到变量`a`中【a[0]是全匹配，a[1]是第一个字表达式】，然后把匹配成功符合结果的`a[1]`输出 

4. `sort`将上述结果排序 [一定要排序，不然去重无效，只会去除相邻的重复项]

5. `uniq -c`将上述结果去重

6. `wc -l`查看总共结果数量